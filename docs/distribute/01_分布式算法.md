#### **数据一致性模型**

- 强一致性
- 弱一致性
  - 不承诺可以立即读到最新写入的值，也不会承诺具体多久之后可以读到；>>> 不一致窗口
- 最终一致性

  - 弱一致性的特例
  - 不一致窗口：主要受通信延迟，系统负载和副本个数的影响
    **写一致性级别**

- Any： 所有节点都没写成功，如果请求成功保存到了**失败重传**的缓存队列中，也算成功。any 是最弱的写一致性级别。

- One：必须写成功一个节点；任何一个节点写入成功后，立即返回成功给客户端

- Quorum：多数节点写入成功后

- All：所有节点都写入成功后，返回成功

#### **Quorum NWR 算法**

三要素：

- N 副本数
- W 写一致性级别 ： 完成 W 个副本更新，才完成写操作
- R 读一致性级别 ： 读取 R 个副本，选最新的日志作为最新数据

一致性效果：

- W+R>N，强一致性
- W+R<=N，最终一致性
  实际场景选择：

- N 表示副本的冗余备份能力
- W=N 时，读性能比较好（读一个就成功了）
- R=N 时，写性能比较好（写一个就成功了）
- W=R=(N+1)/2 时，容错能力比较好，能容忍（N-1）/2 的故障

#### **cap 理论**

一致性，可用性，分区容错 -- 三角不可能

分布式环境，必定存在网络分区，所以分区容错性必须满足，只能选择两种模型：

- cp
- ap

#### **base 理论**

cap 理论的一种妥协，降低了发生分区容错时，对可用性和一致性的要求

- 基本可用：允许可用性降低
- 软状态：允许系统中数据存在中间状态
- 最终一致性：允许数据同步存在时延

实现基本可用的方法：

- 流量削峰、延迟响应、体验降级、过载保护

- 故障隔离

- 弹性扩容

#### **paxos 共识算法**

- 分布式系统如何就某个值达成一致
- 一种思想
  **basic paxos**

- 提案 ： [n, v]，n 为提案编号，v 为提议值
- prepare 准备请求
- accept 接受请求

三种角色

- proposer (提议者)：提议一个值，用于投票表决
- acceptor（接受者）：对每个提议的值进行投票，并存储接受的值
- learner（记录员）：被告知投票的结果，接受达成共识的值，存储保存，不参与投票的过程。

两个阶段：

- 准备阶段（prepare）

  (a) Proposer 选择一个**提案编号 N**，然后向**半数以上**的 Acceptor 发送编号为 N 的**Prepare 请求**。

  (b) Acceptor 收到一个编号为 N 的 Prepare 请求，且 N**大于**该 Acceptor 已经**响应过的**所有**Prepare 请求**的编号

  那么它就会将它已经**接受过的编号最大的提案（如果有的话）**作为响应反馈给 Proposer，同时该 Acceptor 承诺**不再接受**任何**编号小于 N 的提案**。

- 接受阶段（accept)

  (a) 如果 Proposer 收到**半数以上**Acceptor 对其发出的编号为 N 的 Prepare 请求的**响应**，那么它就会发送一个针对**[N,V]提案**的**Accept 请求**给**半数以上**的 Acceptor。注意：V 就是收到的**响应**中**编号最大的提案的 value**，如果响应中**不包含任何提案**，那么 V 就由 Proposer**自己决定**。

  (b) 如果 Acceptor 收到一个针对编号为 N 的提案的 Accept 请求，只要该 Acceptor**没有**对编号**大于 N**的**Prepare 请求**做出过**响应**，它就**接受该提案**。

总结：

- 二阶段提交
- 容错能力：超过半数通过
- 提案编号的大小代表着优先级，通过的最大编号的提案信息

**数据一致性与 paxos 算法**

- 保持数据的一致性的原则：在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行**相同的操作序列**，那么他们最后能得到一个**一致的状态**。

- Paxos 算法**顺序一致性**保证：

  master 维护一个全局写队列，所有写操作都必须放入这个队列**编号**，就能保证顺序一致性

- master 挂了怎么办？
  1. 同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票
  2. 只有获得过半数选票的写操作才会被批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票
  3. 投票中，所有写操作都被严格编号排序，编号严格递增。
  4. 当一个节点接受了一个编号为 100 的写操作，之后又接受到编号为 99 的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己 数据不一致了，自动停止对外服务并重启同步过程。
  5. 任何一个节点挂掉都不会影响整个集群的数据一致性（总`2n+1`台，除非挂掉大于 n 台）。

#### **Multi-Paxos**

- 是一种思想，不是算法
- 选举领导者
- 优化机制：当领导者处于稳定状态时，省掉准备阶段，直接进入接受阶段，优化了`basic paxos`
- 不推荐设计和实现新的 Multi-Paxos 算法，而是建议优先考虑 **Raft 算法**

#### **Raft**

- 分布式一致性算法

- paxos 的实现，属于 Multi-Paxos 算法
- 优先选举出 leader
- 日志必须连续
- 只支持领导者、跟随者、候选人三种状态
- 现在分布式系统开发首选的共识算法（如 Etcd、Consul、CockroachDB）
- 核心思想：通过一切以领导者为准的方式，实现一系列值的共识和各节点日志的一致
- 强领导者模型，集群中只能有一个“领导者”

**三种成员角色：**

- leader 领导者：
  - 处理客户端更新请求
  - 管理日志复制
  - 不断发送心跳消息
- Follower 跟随者：
  - 接收和处理来自领导者的消息
  - 遇到领导者心跳超时，推荐自己为候选人
- Candidate 候选人：

  - 向其他节点发送投票请求（RequestVote）
  - 如果赢得大多数选票，就晋升为领导者
    **Term 任期：**

- 每个任期由单调递增的数字（任期编号）标识
- 任期编号随着选举的举行而变化

  - 跟随者推举自己为候选人时，会增加自己的任期号
  - 发现自己的任期编号比其他节点小，那么它会更新自己的编号到较大的编号值
    **节点间通讯（两个 RPC）：**

- 请求投票（RequestVote）RPC: 候选人在选举期间发起，通知各节点进行投票；包含参数 lastIndex, lastTerm，只有两者都是最新的才会赢得选票
- 日志复制（AppendEntries）RPC: 领导者发起，用来复制日志和提供心跳消息
  **日志序列**：每个节点上保存一份持久化 log，顺序存放

**状态机：**

**选举规则：**

- 领导者周期性向所有跟随者发送心跳
- 指定时间内，跟随者没有收到来自领导的消息，就增加自己本地节点的 term，推举自己为候选人
- 发生选举的情况：
  - 集群初始化时，都是 follower，随机超时
  - 领导者自身出问题（宕机）
  - 网络问题，其他节点没有收到领导者发送的心跳
- 一次选举中，赢得大多数选票的候选人，晋升为领导
- 一次投票中，遵循先来先到原则，每个节点最多会对一个任期编号投出一张选票
- 日志完整性高的跟随者，拒绝投票给日志完整性更低的候选人
  - 日志完整性高的判断：最后一条日志对应的 lastIndex, lastTerm 更大
- 选举结果：
  - 赢得选举：收到大多数投票的节点，切换到 leader，给所有节点发送赢得选举的 majority 心跳
  - 输掉选举：被告知别人当选，切换到 follower 状态
  - 重新选举：一段时间没有收到`majority`和`leader`的心跳通知，保持`candidate`， `term+1`，重新发起选举
    如何避免分裂选票的情况？

多个候选人在同一时间开始选举造成的。例如，一个 5 台服务器的集群，3 台服务器同时开始选举，就有可能出现 2 票、2 票、1 票的情况

**网络分区**

两个 leader 的情况

leader 变成 follower 的唯一条件是收到心跳，但是收到心跳还是要判断 term 的，所以 term 就成为关键了。

**分布式系统的典型应用**

分布式系统是一个非常广泛的概念，它最终要落实到解决实际问题上，不同的问题有不同的方法和架构。所有的开源软件都是以某个应用场景出现，而纯粹以“分布式”概念进行划分的比较少见。
但如果以算法划分，到能分出几类： 1.以 Leader 选举为主的一类算法，比如 paxos、viewstamp，就是现在 zookeeper、Chuby 等工具的主体 2.以分布式事务为主的一类主要是二段提交，这些分布式数据库管理器及数据库都支持 3.以弱一致性为主的，主要代表是 Cassandra 的 W、R、N 可调节的一致性 4.以租赁机制为主的，主要是一些分布式锁的概念，目前还没有看到纯粹“分布式”锁的实现 5.以失败探测为主的，主要是 Gossip 和 phi 失败探测算法，当然也包括简单的心跳 6.以弱一致性、因果一致性、顺序一致性为主的，开源尚不多，但大都应用在 Linkedin、Twitter、Facebook 等公司内部 7.当然以异步解耦为主的，还有各类 Queue
